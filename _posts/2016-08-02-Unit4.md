---
layout: post
title:  "Learnings from a DevOps Hackfest with Unit4"
author: "Aleksandar Dordevic"
author-link: "#"
#author-image: "{{ site.baseurl }}/images/authors/photo.jpg"
date:   2016-06-16
categories: DevOps
color: "blue"
#image: "{{ site.baseurl }}/images/imagename.png" #should be ~350px tall
excerpt: Microsoft worked with Unit4 to establish DevOps practices.
---
# Learnings from a DevOps Hackfest with Unit4

Unit4, a large, independent software vendor, reached out to Microsoft DX Netherlands, wanting to accelerate their Azure cloud adoption and find support for their DevOps efforts. We teamed up and agreed to jointly hack Unit4’s *Business World On!* solution and its components. 

This report describes how Unit4, Chef, and Microsoft collectively applied DevOps practices at an enterprise level and what lessons we learned in the process. It explains which DevOps practices we implemented in this particular hack, including:

* Infrastructure as Code (IaC)
* Continuous Integration (CI)
* Continuous Deployment (CD)
* Release Management (RM)
* Configuration Management (CM)

### The hack team

The team for this engagement consisted of the following participants from Unit4, joined by IT professionals from Chef and Microsoft. 

Unit4:

* Øivind Rype – developer
* Arve Svendsen – head of technical domain 
* Bård Eik-Hvidsten – developer
* Einar Onsum – delivery/deployment engineer 
* Magnus Tengmo – DBA and architect 
* Conny Zell – developer 
* Åsmund Riiser Kristiansen – developer 
* Mirosław Coma – cloud ops 
* Erik Marcussen – technical platform lead (dev) 
* Jon Braathen – developer 
* Mariusz Konarski – cloud ops 
* Ryan Gloeckler – principal cloud architect 
* Pasi Tuukkanen – global cloud operations lead 
* Svanhild Odden – developer 
* Jon Braathen – developer
* Lars Fredrik Hatlehol – developer
* Claus Jepsen – chief architect
 
Chef:

* Yvo van Doorn – EMEA technical services manager
* Joe Gardiner – solutions architect

Microsoft:

* Astrid Hackenberg – senior software developer 
* Greg Oliver – senior software developer
* Stuart Leeks – senior software developer
* Marco van der Kooij – partner development evangelist 
* Rasmus Hald ([@RasmusHaldDK](https://twitter.com/@RasmusHaldDK)) – principal technical evangelist 
* Aleksandar Dordevic ([@Alex_ZZ_](https://twitter.com/Alex_ZZ_)) – principal technical evangelist

## Customer profile
[Unit4](http://www.unit4.com/) is a leading provider of enterprise applications used by thousands of organizations worldwide. Its solutions are in use among sectors providing professional services, education, public services, non-profit, real estate, wholesale, and financial services. It has approximately 4,000 employees. 

The Hackfest partnership began with a meeting of the Unit4 and Microsoft teams at Microsoft in The Netherlands. The Unit4 team was responsible for cloud adoption and transformation of their Dev and Ops teams, and finding ways to create and deliver software to their clients. We discussed their current way of working and how to reinvent it toward more agile teams and ways of operating. During this meeting we narrowed the options to executable/doable steps that would be inline and helpful to their DevOps journey. 

We decided to deliver a Value Stream Map (VSM) workshop followed by a DevOps Hackfest. We would deliver this engagement in two steps: first, a one-day VSM workshop in mid-March 2016; second, a three-day Hackfest in May 2016.

A few months after our initial meeting, the joint team convened at Unit4’s office in Oslo, Norway, for the Value Stream Map workshop and to capture how Unit4 conceives ideas, makes user stories, develops new features, tests new code, and ultimately moves deployables via different environments. 

But before delivering the VSM workshop, we focused on the high-level architecture of the solution. We needed everyone to be in alignment on how the *Business World On!* solution works and what the major building blocks are. 

*Figure 1: High-level architecture*

![](/images/Unit4_1.jpg)

*Business World On!* is an Enterprise Resource Planning (ERP) type of solution, one of many solutions Unit4 has in its large portfolio of services. From a user perspective, Business World On! had spanned from a desktop-rich endpoint to mobile and browser usage of the application. Most of the business logic is embedded in a module at the front end and central database. These two components are the heart of the system, while other components are in service at the core of the system. Client access and reporting layers are separated in adequate individual components. 

We simplified and deconstructed the app structure into these fundamental building blocks:

* Endpoint access layer with pluggable modules
* DB layer 
* Background worker roles / batch jobs

It is important to note that at the time of the Hackfest, Unit4 was leveraging its production solution via an internal private cloud based on virtual machines. Their company goal was to use the Microsoft cloud and optimize code and deployment to support it—they wanted to be fully “cloud ready,” both from a development and operations perspective. Unit4 already had started this cloud journey and we were pleased to be able to see the current state, work on accelerating the transformation, and finally create tangible and measurable elements together with them.

## Problem statement

In order to identify bottlenecks and areas in need of improvement, the team crafted a full value stream, from idea creation to delivery in production. This Value Stream Map exercise lasted a full day, but it was worth the effort. For the first time, the team saw the overall process of creating and delivering value with the *Business World On!* application. 

*Figure 2: Mapping the full value stream of the application*

![](/images/Unit4_2.jpg)

The team was now able to visualize the value and the workflow, see how it intersects departments, and identify areas with wasteful activities. This led to interesting open discussions, exchanges of ideas, and various countermeasure proposals.

The following figure shows the results of our Value Stream Mapping workshop.

*Figure 3: Results of the Value Stream Mapping workshop*

![](/images/Unit4_3.jpg)

We used the most recent successful release of the *Business World On!* application for the VSM exercise. 

Based on the VSM results, we identified the areas with the most pain as **development** and **release**. The types of problems were very common and frequently seen in large development teams: large batch size and lack of automation while releasing code to staging and production. 
   
Their development process took place in a three-week sprint and, depending on the complexity of the feature, could take up to 15 sprints before it moved on to the next step of the value flow. An additional discovery was that multiple features were developed at the same time, creating a “siloed” mode of working for the team. The team discussed how to tackle this challenge and what is affected by it. We quickly concluded that small batch is the key and that the pipeline needs to be adjusted to support it.

From a release standpoint, we saw that lead time of deployment to different environments can take up to 10 weeks and most of that work was being done manually. The team proposed Infrastructure as Code (IaC) as one of the countermeasures. In addition, after more open and creative discussion, the team proposed implementing Release Management practices along with IaC in order to fully respect and comply with Unit4’s company policies. This was significant because it led to Unit4’s decision to choose our partner Chef and its capabilities to deliver IaC.

Here is a summary of the identified countermeasures and recommendations agreed on by the team after the VSM workshop: 

* **Implement IaC and Configuration Management**
  * Automate deployment to different environments, both staging and production, and use IaC and Release Management practices (Team Foundation Server, Visual Studio Team Services, and/or other tools of preference). 
* **Implement Release Management (RM)**
  * Automate deployment and testing to the staging environment. 
* **Implement Continuous Integration and Continuous Deployment (CI/CD)**
* **Use Azure Platform as a Service (PaaS) capabilities in the future app development/release**
  * Web tier of the app solution (currently virtual machines) could/should be tested to move to Azure Web Apps or, in the future, to Azure Service Fabric (work in progress).
  * SQL tier of the app solution (currently virtual machines) could/should be tested to move to Azure SQL Database (work in progress).
* **Innovate development process and people skill development**
  * Leverage innovation and accelerate future feature development by planning and scheduling development/use of new skills/practices/tools as standard and planned work.
  * Create smaller deployment batches, drive development toward continuous innovation.
  * Invest in efforts to lower technical debt.
  
*Figure 4: Participants in the Value Stream Mapping workshop*

![](/images/Unit4_4.jpg)

The Value Stream Map workshop was key to defining a focus for the upcoming DevOps Hackfest, both its execution and solution aims. Unit4 decided that the most valuable achievement for them would be to prototype the velocity of pushing new features, test development for and with the cloud, and test deployment to the multiple cloud environments. In addition, since Unit4 had the *Business World On!* solution on premises and were keen to take it to the Azure cloud, it was crucial to cover Infrastructure as a Service (virtual machines) and PaaS delivery.

Everyone on the team accepted these tasks and began preparing for the Hackfest that would occur one month later.

## Solution, steps, and delivery 
In the interest of Unit4’s cloud development goals and to test the identified countermeasures, the team decided to hack Identity Services, the production component of *Business World On!* (The *Business World On!* app itself would be too “bulky” to be hacked in three days.) Unit4 suggested using Identity Services because it is a component of many of their solutions, it is security-related, and it would be a proper proof of concept (PoC) for them. In addition, this was a great opportunity to experiment with small batch size and velocity of pushing changes to production environments. 

The initial measurable starting points for the Identity Services app were the following:

* Deployment lead time ~5 days (to provision and configure new customer/client)
* Developing and delivering hotfix, total lead time ~3 weeks
* A few scripts that needed to be run manually

We as a team were determined to dramatically improve these numbers.

In brief, the Identity Services component is a claim-based component that runs as a web service and relies on a database and digital certificate to deliver its function. The following image shows the high-level blocks of the app. 

*Figure 5: The high-level blocks of the application*

![](/images/Unit4_5.png)

Before getting into technical achievements and nuggets, here is a look at the plan for how the overall process and architecture should look and what key milestones should be delivered as a result of the hack.
 
We envisioned this as a solution:

*Figure 6: The solution that the team envisioned*

![](/images/Unit4_6.png)

We had a single code source and the output of that source needed to be deployed in two different environments—IaaS and PaaS. That led to the planning of the appropriate architecture that will provide the needed functionality, availability, and security that this type of solution requires. We brainstormed as a team and created an architecture that would enable us to start the hack. Here, side by side, is what IaaS versus PaaS architecture looks like:

*Figure 7: IaaS architecture versus PaaS architecture*

![](/images/Unit4_7.png)

Now let’s take a look at the most interesting technical achievements delivered at this DevOps Hackfest that supported planned architecture and set goals.
  
It is difficult to decide which one or two nuggets are *the* best to share, but here are my choices. I’ll aggregate to cover the whole pipeline, in major blocks, and to show how some of it was done at PaaS versus IaaS to achieve the same functionality.

### Infrastructure as Code
We all struggle with the correct way to handle and use secrets, certificates, and so forth. During the Hackfest we discovered a way to push and hand over the needed certificate to Azure Web Apps in an automated and secure way. In addition, we enabled scenarios in which the deployment team just refers to the secrets, in the delivery phase, while the security team, for example, maintains and manages [Azure Key Vault](https://azure.microsoft.com/en-us/services/key-vault/).
 
Assuming you have successfully put your secrets in Azure Key Vault, here is how to reference those secrets in the Azure Resource Manager (ARM) template. In our case, we wanted cert, with private and public key, to be automatically available to the environment during provisioning of infrastructure.

In the following code, you will see snippets of the ARM template and a corresponding parameter file that enables you to make a reference to the Azure Key Vault secrets.

Snippet code from the ARM template file:

{% highlight groovy %}
{
      "apiVersion": "2015-08-01",
      "name": "[concat(parameters('webSiteName'), '-cert')]",
      "type": "Microsoft.Web/certificates",
      "tags": {
        "displayName": "cert"
      },
      "location": "[resourceGroup().location]",
      "properties": {
        "pfxBlob": "[parameters('cert')]",
        "password": "[parameters('certpassword')]"
      }
    },

    {
      "apiVersion": "2015-08-01",
      "name": "[parameters('webSiteName')]",
      "type": "Microsoft.Web/sites",
      "location": "[resourceGroup().location]",
      "dependsOn": [
        "[concat('Microsoft.Web/serverFarms/', parameters('hostingPlanName'))]",
        "[concat('Microsoft.Storage/storageAccounts/', variables('logstorageName'))]"
      ],
      "tags": {
        "[concat('hidden-related:', resourceGroup().id, '/providers/Microsoft.Web/serverfarms/', parameters('hostingPlanName'))]": "empty",
        "displayName": "Website"
      },
      "properties": {
        "name": "[parameters('webSiteName')]",
        "serverFarmId": "[resourceId('Microsoft.Web/serverfarms', parameters('hostingPlanName'))]"
      },
      "resources": [
        {
          "apiVersion": "2015-08-01",
          "type": "config",
          "name": "appsettings",
          "dependsOn": [
            "[concat('Microsoft.Web/Sites/', parameters('webSiteName'))]",
            "[concat('Microsoft.Cache/Redis/', parameters('RedisName'))]",
            "[concat('Microsoft.Web/certificates/', parameters('webSiteName'), '-cert')]"
          ],
          "properties": {
            "cache:type": "redis",
            "cache:default-duration": "60",
            "cache:redis-configuration": "[concat(reference(concat('Microsoft.Cache/Redis/', parameters('RedisName'))).hostName, ':6380,password=', listKeys(resourceId('Microsoft.Cache/Redis', parameters('RedisName')), '2015-08-01').primaryKey, ',ssl=True,abortConnect=False')]",
            "admin:api:authentication:basic:username": "[parameters('idserver-username')]",
            "admin:api:authentication:basic:password": "[parameters('idserver-password')]",
            "admin:api:authentication:type": "basic",
            "SigningCertificateThumbprint": "[reference(concat('Microsoft.Web/certificates/', parameters('webSiteName'), '-cert')).thumbprint]",
            "WEBSITE_LOAD_CERTIFICATES": "[reference(concat('Microsoft.Web/certificates/', parameters('webSiteName'), '-cert')).thumbprint]"
          }
        }
      ],
{% endhighlight %}

In the snippet code above, you can find the **[concat(parameters('webSiteName'), '-cert')]** resource that is “pooling” the certificate from Azure Key Vault. The **Signing Certificate** and **WEBSITE_LOAD_CERTIFICATES** configuration under the WebSite resource is configuring Azure Web Apps to make use of the supplied certificate. As you see in the code, we are referencing the **pfxBlob** and **password** properties of the resource cert to a parameter file. Here is a look at what is important to be set there.

The corresponding ARM parameters file:

{% highlight groovy %}

    "cert": {
      "reference": {
        "keyVault": { "id": "/subscriptions/<ID>/resourceGroups/hacksecrets/providers/Microsoft.KeyVault/vaults/hackvault" },
        "secretName": "hackcert"
      }
    },
    "certpassword": {
      "reference": {
        "keyVault": { "id": "/subscriptions/<ID> /resourceGroups/hacksecrets/providers/Microsoft.KeyVault/vaults/hackvault" },
        "secretName": "hackcertpwd",
        "secretVersion": "zxcx5dabcb6d4e44a334649c3132vcxz"
      }
    }
{% endhighlight %}

In the parameter file you are defining a “location” in Azure Key Vault from where, during the provisioning, ARM will pick up the needed certificate and password. 

Here is the result on the Azure portal and how it looks when successfully deployed:

*Figure 8: The result on the Azure portal and how it looks when successfully deployed*

![](/images/Unit4_81.png)

### Configuring web server with Chef
Now that we have shown how to pass and configure an application securely with the needed certificate in a PaaS setup, let’s see how the team achieved it in an IaaS environment. 

I’ll briefly explain how Chef did the overall configuration. We had all virtual machines automatically configured with a Chef extension—it was done with the appropriate ARM template during the initial phase of infrastructure provisioning. After that, all configuration management was done by Chef. 

As noted earlier, let’s now see how in the IaaS world you can get the same scale of configuration with Chef, with regard to passing certificate and application configuration to the infrastructure environment.

Here is a recipe for installing a certificate on all front-end virtual machines—our PoC had two front-end nodes.

*Figure 9: A recipe for installing a certificate on all front-end virtual machines*

![](/images/Unit4_9.png)

Corresponding code from the ssl.rb file:

{% highlight ruby %}

# Cookbook Name:: IdentityServices
# Recipe:: ssl
#
# Copyright (c) 2016 The Authors, All Rights Reserved.

# Create directory for storing certificate
directory 'C:\UNIT4\#Certificates' do
  recursive true
    action :create
end

# Copy the certificate onto the node
cookbook_file 'C:\UNIT4\#Certificates\cert.pfx' do
  source 'cert.pfx'
    action :create
  not_if { ::File.exist?('C:\UNIT4\#Certificates\complete.txt') }
end

# Install certificate
windows_certificate 'C:\UNIT4\#Certificates\cert.pfx' do
  pfx_password '###########'
    action :create
  not_if { ::File.exist?('C:\UNIT4\#Certificates\complete.txt') }
end

# create completion file
file 'C:\UNIT4\#Certificates\complete.txt' do
    action :create_if_missing
    notifies :create, 'windows_certificate_binding[*.u4demo.com]', :immediately
end

# Bind the cert to 443 in personal store
windows_certificate_binding '*.u4demo.com' do
    name_kind :subject
  store_name 'MY'
  port 443
    action :nothing
end

# Tidy up
file 'C:\UNIT4\#Certificates\cert.pfx' do
    action :delete
end

{% endhighlight %}

See the Resources section for more information on SSL Chef recipes. 

IaC is set up to check on whether a certificate exists, and if not to force its installment, binding to the appropriate port and finally doing a cleanup so we don’t leave a PFX file on the file system. Once all nodes have the appropriate certificate, the next step is to configure the application, Identity Service, to use it. This is done by pushing to Internet Information Services (IIS) **web.conf** configuration to all virtual machines and front-end nodes. 

The team created a template, **webconfig.erb**, and was referring to it in one of the cookbooks—take a look:

*Figure 10: Cookbook refers to webconfig.erb*

![](/images/Unit4_10.png)

See the Resources section at the end of this report for links to more Chef documentation. 

Let’s zoom in to the specific place at webconfig.erb where the application is getting the needed setting.

Because we previously installed cert on virtual machines, it is now only a matter of “telling” the app to start to use it.

*Figure 11: Closer look at webconfig.erb*

![](/images/Unit4_11.png)

As the code below shows, we are referencing configuration of the app to look and use a previously imported certificate. This way we ensured that application, Identity Service, has all the prerequisites (DB connection string, signing certificate, and so forth) to run smoothly on “n” number of front-end virtual machines. 

Here is a snippet of the code used to address signing certificate and connection strings inside the **webconfig.erb** file:

{% highlight groovy %}

<!--GENERAL SETUP-->
    <add key="identityserver:providers:saml2:entity-id" value="https://<%= node['hostname'] %>.u4demo.com//IdentityService/identity"/>

    <!--SECURE SETUP-->
    <add key="security-policy:hsts:max-age" value="30"/>
    <!--Signing certificates-->
    <!-- Allowed values: Localmachine,CurrentUser-->
    <add key="SigningCertificateStoreLocation" value="Localmachine"/>
    <!-- Allowed values: Personal, TrustedRootCAs, OtherUsers,TrustedPeople    -->
    <add key="SigningCertificateStoreName" value="PERSONAL"/>
    <add key="SigningCertificateThumbprint" value="<%= node['identity']['certificate']['thumbprint'] %>"/>  

<!-- other standard configuration data continues ... -->

<connectionStrings>
  <add name="U4IDSConfig" providerName="System.Data.SqlClient" connectionString="Server=<%= node['identity']['database']['hostname'] %>;Initial Catalog=<%= node['identity']['database']['dbname'] %>;User Id=<%= node['identity']['database']['user'] %>;Password=<%= node['identity']['database']['password'] %>"/>
</connectionStrings>

{% endhighlight %}

### Build definitions 
Here is the unfiltered build definition, which shows how we progressed. For example, the first milestone was to have CI/CD without RM, so that is why some items are disabled. As we managed to get to the milestone with RM, we kept the build steps and disabled them so that we could share those learnings with others. 

Here is how our **PaaS Build definition** looked:

*Figure 12: How the PaaS Build definition looked*

![](/images/Unit4_12.png)

It is more or less a standard build for the web app. One interesting point at this stage is publishing “Infra_Resources.” This step takes IaC scripts and templates from source control and publishes them to the Release Management component of our overall pipeline.

### Release definitions 
We created two release/delivery pipelines to reflect both worlds in which the application needed to live (IaaS and PaaS): **U4IDA Global Cloud** and **U4IDA Local Cloud**. Unit4 Global Cloud = Azure; Local Cloud = on-prem datacenter and/or customer datacenter.

Both release definitions on Visual Studio Team Services (VSTS):

*Figure 13: Both release definitions on Visual Studio Team Services (VSTS)*

![](/images/Unit4_13.png)

Now let’s explore Global Cloud and see how the team used technical capabilities in order to comply with Unit4 policies and delivery plan. Here are the details of the **U4IDA Global Cloud Release Management** definition, high level:

*Figure 14: High-level details of the U4IDA Global Cloud Release Management definition*

![](/images/Unit4_14.png)

The Global Cloud definition has two stages (environments) of application lifecycle: staging and production. Each stage has its own steps/tasks that are executed so the application, its configuration and infrastructure are deployed correctly and in order. After a successful build, Release Management automatically picks up the build artifacts and starts to carry out four steps related to the staging environment. If we break down those steps, we are achieving the following:

* Creating/updating of infrastructure
* Pushing new code to the staging environment
 
When new code is successfully pushed to staging, that code must be approved before it can move to the production environment. According to Unit4 policies, the product owner and head of operations must provide approval to go live to production, so we included that in our Release Management criteria. Here is how we configured it:

*Figure 15: Configuration of approval for release to production*

![](/images/Unit4_15.png)

Once Release Management gets both approvals, it proceeds with carrying out the tasks that are configured. The successful result of Release Management looks like this:

*Figure 16: A successful release to production*

![](/images/Unit4_16.png)

## Conclusion 
It was wonderful to see and contribute to Unit4’s pursuit of more agile ways of developing and delivering software. In addition to the passion shown by the Unit4 technical team, it was clear that Unit4’s board cared about DevOps and transformation as well. The high point of the engagement was the opportunity to demonstrate our achievements to Unit4’s senior leadership team (SLT). 

These are some facts that we shared with the SLT:

* Lead time for provisioning a new environment (or customer) was **reduced from ~5 working days to a maximum of 30 minutes** (depending on whether it is IaaS or PaaS).
* Lead time for pushing a new feature and/or bug fix was **reduced from ~2 weeks to ~15 minutes in an IaaS environment or ~7 minutes in a PaaS environment**.

Other highlights:

* Demonstrated full automated delivery pipeline with IaC versus mostly manual deployment.
* Worked as one team—Dev, Ops, and Architects!
* **Made 72 changes during the three-day Hackfest and successfully pushed them via the pipeline.**

*Figure 17: The team made 72 changes during the Hackfest*

![](/images/Unit4_17.png)

A key takeaway is this: Enterprises are successfully adopting and applying DevOps. Unit4 is doing it and will continue to do so.

This is how we ended our team presentation to the SLT.

*Figure 18: Final summary to senior leaders*

![](/images/Unit4_18.png)

All of this was possible because of teamwork and great people. We successfully delivered all must-have milestones, and most nice-to-have milestones. The credit goes to each involved individual who made this happen—thank you, team!

## Resources 
For more information on Resource Manager and Key Vault:

* [Azure Key Vault](https://azure.microsoft.com/en-us/services/key-vault/)
* [Key Vault secret with Resource Manager template](https://azure.microsoft.com/en-us/documentation/articles/resource-manager-keyvault-parameter/)
* [Using Certificates in Azure Websites Applications](https://azure.microsoft.com/en-us/blog/using-certificates-in-azure-websites-applications/)  

A good starting point for more information on Chef and Microsoft Azure:

* [Microsoft Azure docs @Chef_Web](https://docs.chef.io/azure_portal.html) 
* [Azure-Chef-extension](https://github.com/chef-partners/azure-chef-extension)
* [SSL_certificate cookbook @Chef_Supermarket](https://supermarket.chef.io/cookbooks/ssl_certificate)
* [Configure IIS and ASP.NET](https://learn.chef.io/manage-a-web-app/windows/configure-iis)
* [Configure the web application](https://learn.chef.io/manage-a-web-app/windows/configure-the-web-application) 

